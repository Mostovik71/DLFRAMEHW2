{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.read_csv('../data/IMDB/movie_characters_metadata.tsv',\n",
    "                         sep='\\t',\n",
    "                         warn_bad_lines=False,\n",
    "                         error_bad_lines=False,\n",
    "                         header=None\n",
    "                         )\n",
    "conversations = pd.read_csv('../data/IMDB/movie_conversations.tsv',\n",
    "                            sep='\\t',\n",
    "                            warn_bad_lines=False,\n",
    "                            error_bad_lines=False,\n",
    "                            header=None\n",
    "                            )\n",
    "\n",
    "lines = pd.read_csv('../data/IMDB/movie_lines.tsv',\n",
    "                    sep='\\t',\n",
    "                    warn_bad_lines=False,\n",
    "                    error_bad_lines=False,\n",
    "                    header=None\n",
    "                    )\n",
    "titles = pd.read_csv('../data/IMDB/movie_titles_metadata.tsv',\n",
    "                     sep='\\t',\n",
    "                     warn_bad_lines=False,\n",
    "                     error_bad_lines=False,\n",
    "                     header=None\n",
    "                     )\n",
    "\n",
    "characters.columns = ['characterID', 'character', 'movieID', 'movie_title',\n",
    "                      'gender',\n",
    "                      'position']\n",
    "conversations.columns = ['characterID_1', 'characterID_2', 'movieID', 'chrono']\n",
    "lines.columns = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "titles.columns = ['movieID', 'movie_title', 'movie_year', 'rating', 'imdb_votes', 'genres']\n",
    "\n",
    "lines.dropna(inplace=True)\n",
    "conversations.dropna(inplace=True)\n",
    "titles.dropna(inplace=True)\n",
    "characters.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9defb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrn(s, delim=' '):\n",
    "    s1 = ast.literal_eval(s)\n",
    "    to_ret = [delim + i for i in s1[0].split(delim)[1:]]\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnr(s):\n",
    "    to_ret = [i[1:-1] for i in s.strip('][').split(' ')]\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Data preparing\n",
    "\n",
    "lns_chrs = dict(zip(lines.lineID, lines.characterID)) # Маппинг персонажей\n",
    "lns = dict(zip(lines.lineID, lines.text)) # Маппинг текста\n",
    "chars = dict(zip(characters.characterID, characters.character)) # Маппинг имен\n",
    "floor = dict(zip(characters.characterID, characters.gender)) # Маппинг пола\n",
    "\n",
    "titles['genres'] = titles['genres'].apply(lambda x: gnr(x))\n",
    "titles_new = titles[['movieID', 'movie_title', 'genres']]\n",
    "\n",
    "conversations['chrono'] = conversations['chrono'].apply(lambda x: chrn(x, delim='L'))\n",
    "conversations['characters'] = conversations['chrono'].apply(lambda x: [lns_chrs[i] if i \\\n",
    "                                                                       in lns_chrs.keys() else 'unknown_character' for i in x])\n",
    "\n",
    "conversations['genders'] = conversations['characters'].apply(lambda x: [floor[i] if i \\\n",
    "                                                                        in floor.keys() else '?' for i in x])\n",
    "\n",
    "conversations['replics'] = conversations['chrono'].apply(lambda x: [lns[i] if i \\\n",
    "                                                                    in lns.keys() else 'unknown_text'for i in x])\n",
    "\n",
    "conversations['names'] = conversations['characters'].apply(lambda x: [chars[i] if i \\\n",
    "                                                                      in chars.keys() else 'unknown_character 'for i in x])\n",
    "\n",
    "conversations_new = conversations[['movieID', 'chrono', 'characters', \n",
    "                                   'genders', 'replics', 'names']]\n",
    "\n",
    "\n",
    "\n",
    "df = conversations_new.merge(titles_new, on='movieID', how='left')\n",
    "#df.to_csv('films_prepared_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('films_prepared_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecd290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replics = df.replics.apply(lambda x: eval(x))\n",
    "df.names = df.names.apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75fd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.iloc[5527]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataset_torch(data: list):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for row in data:\n",
    "        encoded_dict = tokenizer.encode_plus(row, \n",
    "                                             max_length=130,\n",
    "                                             pad_to_max_length=True,\n",
    "                                             return_attention_mask=True, \n",
    "                                             return_tensors='pt', \n",
    "                                             truncation=True)\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    input_ids.to(dtype=torch.long)\n",
    "    attention_masks.to(dtype=torch.long)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = convert_to_dataset_torch(sample.replics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596544f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_ids=converted[0], \n",
    "      attention_mask=converted[1]).logits\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ba32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'Positive',\n",
    "    'Negative',\n",
    "    'Neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c781ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {i: k for i, k in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5764f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(torch.nn.Softmax()(preds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = pd.DataFrame({'Speaker': sample.names,\n",
    "                         'Text': sample.replics,\n",
    "                         'Emotion': list(map(lambda x: mapping.get(x, None), predictions.numpy()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = df_local.groupby('Speaker')['Emotion'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78bac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "total_axes = df_local.Speaker.nunique()\n",
    "subplt = 1 # номер начального axes\n",
    "for x in emotion.index.get_level_values('Speaker').unique():\n",
    "    ax = fig.add_subplot(1, total_axes, subplt) # добавляем axes для каждого графика\n",
    "    plt.pie(emotion[x], labels=emotion[x].index.tolist(), autopct='%1.1f%%')\n",
    "    plt.xlabel(x)\n",
    "    subplt+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
